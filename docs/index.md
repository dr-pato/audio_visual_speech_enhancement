---
title: Face Landmark-based Speaker-Independent Audio-Visual Speech Enhancement in Multi-Talker Environments
layout: default
---

## Abstract
We address the problem of enhancing the speech of a speaker of interest in a cocktail party scenario when visual information of the speaker of interest is available. Contrary to most previous studies, we do not learn visual features on the typically small audio-visual datasets, but use an already available face landmark detector (trained on a separate image dataset). The landmarks are used by LSTM-based models to generate time-frequency masks which are applied to the acoustic mixed-speech spectrogram. Results show that: (i) landmark motion features are very effective features for this task, (ii) similarly to previous work, reconstruction of the target speakerâ€™s spectrogram mediated by masking is significantly more accurate than direct spectrogram reconstruction, and (iii) the best masks depend on both motion landmark features and the input mixed-speech spectrogram. To the best of our knowledge, our proposed models are the first models trained and evaluated on the limited size GRID and TCD-TIMIT datasets, that achieve speaker-independent speech enhancement in a multi-talker setting.

<div align="center">
<iframe
width="800" height="450" src="https://www.youtube.com/embed/YQ0q-OFphKM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>

## Demos
The following videos contains severals examples of enhanced speech generated by models proposed in our paper.

### GRID corpus

<div align="center">
<table id="mytable" border="0">
  <tr>
    <th>2-Speakers Mix</th>
    <th>3-Speakers Mix</th> 
  </tr>
  <tr>
    <td>
		<video width="380" height="317" controls>
		<source src="videos/grid_2spk.mp4" type="video/mp4">
		Your browser does not support the video tag.
		</video>
	</td>
    <td>
		<video width="380" height="317" controls>
		<source src="videos/grid_3spk.mp4" type="video/mp4">
		Your browser does not support the video tag.
		</video>
	</td> 
  </tr>
</table>
</div>

### TCD-TIMIT corpus

<div align="center">
<table>
  <tr>
    <th>2-Speakers Mix</th>
    <th>3-Speakers Mix</th> 
  </tr>
  <tr>
    <td>
		<video width="380" height="317" controls>
		<source src="videos/timit_2spk.mp4" type="video/mp4">
		Your browser does not support the video tag.
		</video>
	</td>
    <td>
		<video width="380" height="317" controls>
		<source src="videos/timit_3spk.mp4" type="video/mp4">
		Your browser does not support the video tag.
		</video>
	</td>
  </tr>
</table>
</div>

## Paper
The paper is available [here](https://arxiv.org/abs/1811.02480). If this project is useful for your reserch, please cite:
```
@inproceedings{morrone2019face,
  title={Face Landmark-based Speaker-Independent Audio-Visual Speech Enhancement in Multi-Talker Environments},
  author={Morrone, Giovanni and Bergamaschi, Sonia and Pasa, Luca and Fadiga, Luciano and Tikhanoff, Vadim and Badino, Leonardo},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6900-6904},
  year={2019},
  organization={IEEE}
}
```
